{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year       int64\n",
      "month      int64\n",
      "meant    float64\n",
      "maxtp    float64\n",
      "mintp    float64\n",
      "mnmax    float64\n",
      "mnmin    float64\n",
      "rain     float64\n",
      "gmin      object\n",
      "wdsp      object\n",
      "maxgt     object\n",
      "sun       object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#download data, organize into arrays\n",
    "\n",
    "df = pd.read_csv(\"mly2275.csv\", comment='#')\n",
    "#print(df.head())\n",
    "\n",
    "X1=df.iloc[:, 0]\n",
    "X2=df.iloc[:, 1]\n",
    "\n",
    "#making X an array of dates \n",
    "X=[]\n",
    "for i in range(np.size(X1, 0)):\n",
    "    X.append(datetime.date(X1[i], X2[i], 1))\n",
    "X=np.array(X)\n",
    "\n",
    "y1=df.iloc[:, 2]\n",
    "y2=df.iloc[:, 3]\n",
    "y3=df.iloc[:, 4]\n",
    "y4=df.iloc[:, 5]\n",
    "y5=df.iloc[:, 6]\n",
    "y6=df.iloc[:, 7]\n",
    "y7=df.iloc[:, 8] \n",
    "y8=df.iloc[:, 9]\n",
    "y9=df.iloc[:, 10]\n",
    "y10=df.iloc[:, 11]\n",
    "\n",
    "print(df.dtypes) #some of our columns came out as 'object' (string) --> we'll have to fix that\n",
    "#                --> where the data's missing, use average of 2 surrounding points It's not perfect, but should be sufficient\n",
    "\n",
    "for i in range(np.size(y7, 0)):\n",
    "    if y7[i]=='None':\n",
    "        y7[i]=(float(y7[i-1])+float(y7[i+1]))/2\n",
    "y7=y7.astype(float)\n",
    "for i in range(np.size(y8, 0)):\n",
    "    if y8[i]=='None':\n",
    "        y8[i]=(float(y8[i-1])+float(y8[i+1]))/2\n",
    "y8=y8.astype(float)\n",
    "for i in range(np.size(y9, 0)):\n",
    "    if y9[i]=='None':\n",
    "        y9[i]=(float(y9[i-1])+float(y9[i+1]))/2\n",
    "y9=y9.astype(float)\n",
    "for i in range(np.size(y10, 0)):\n",
    "    if y10[i]=='None':\n",
    "        y10[i]=None\n",
    "y10=y10.astype(float)\n",
    "\n",
    "#we're not including hours of sun in our data, because it's missing for the past decade\n",
    "y=np.column_stack((y1, y2, y3, y4, y5, y6, y7, y8, y9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea3b216e6514c4c917aa5218a88ef97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbfba50a5464439a1c17b2752851073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#visualise data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "#timeline - each variable on its own\n",
    "\n",
    "f=plt.figure(figsize=(10,15))\n",
    "f.add_subplot(10, 1, 1)\n",
    "plt.plot(X, y1, color='orange', label='mean temp')\n",
    "f.add_subplot(10, 1, 2)\n",
    "plt.plot(X, y2, color='red', label='max temp')\n",
    "f.add_subplot(10, 1, 3)\n",
    "plt.plot(X, y3, color='blue', label='min temp')\n",
    "f.add_subplot(10, 1, 4)\n",
    "plt.plot(X, y4, color='red',linestyle='dashed', label='mean max temp')\n",
    "f.add_subplot(10, 1, 5)\n",
    "plt.plot(X, y5, color='blue',linestyle='dashed', label='mean min temp')\n",
    "f.add_subplot(10, 1, 6)\n",
    "plt.plot(X, y6, color='lightsteelblue', label='rain')\n",
    "f.add_subplot(10, 1, 7)\n",
    "plt.plot(X, y7, color='green', label='grass mean temp')\n",
    "f.add_subplot(10, 1, 8)\n",
    "plt.plot(X, y8, color='plum', label='wind')\n",
    "f.add_subplot(10, 1, 9)\n",
    "plt.plot(X, y9, color='purple', label='highest gust')\n",
    "f.add_subplot(10, 1, 10)\n",
    "plt.plot(X, y10, color='gold', label='sun') #note that sun data disappears around 2010 - 2015\n",
    "f.legend()\n",
    "plt.show()\n",
    "\n",
    "#last 30 yrs - comparing variables that seem related --> slice [612:None]\n",
    "f=plt.figure(figsize=(10,9))\n",
    "f.add_subplot(4, 1, 1)\n",
    "plt.plot(X[612:None], y1[612:None], color='orange', label='mean temp')\n",
    "plt.plot(X[612:None], y2[612:None], color='red', label='max temp')\n",
    "plt.plot(X[612:None], y3[612:None], color='blue', label='min temp')\n",
    "plt.legend()\n",
    "f.add_subplot(4, 1, 2)\n",
    "plt.plot(X[612:None], y4[612:None], color='red', label='mean max temp')\n",
    "plt.plot(X[612:None], y5[612:None], color='blue', label='mean min temp')\n",
    "plt.legend()\n",
    "f.add_subplot(4, 1, 3)\n",
    "plt.plot(X[612:None], y6[612:None], color='lightsteelblue', label='rain')\n",
    "plt.plot(X[612:None], y10[612:None], color='gold', label='sun') #note that sun data disappears around 2010 - 2015\n",
    "plt.legend()\n",
    "f.add_subplot(4, 1, 4)\n",
    "plt.plot(X[612:None], y8[612:None], color='plum', label='wind')\n",
    "plt.plot(X[612:None], y9[612:None], color='purple', label='highest gust')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep data for model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#transform X datetime into a numerical value for the model\n",
    "X1=[]; X2=[]\n",
    "for z in range(np.size(X)):\n",
    "    X1.append(X[z].year)\n",
    "    X2.append(X[z].month)\n",
    "X1=np.array(X1);X2=np.array(X2)\n",
    "X=np.column_stack((X1, X2, (X1*12+X2).reshape(-1, 1)))\n",
    "poly = PolynomialFeatures(4)\n",
    "X = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 Nov\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476414041ca741daaa9511eabca78b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d564eb2fae4dbe859e62fc3b8734b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ridge Regression\n",
    "C_range=[1,2, 3, 4, 5]\n",
    "MSE=[]\n",
    "std_error=[]\n",
    "for C in C_range:\n",
    "    ridge= Ridge(alpha=1/(2*C))\n",
    "    kf = KFold(n_splits=5)\n",
    "    temp=[]\n",
    "    for train, test in kf.split(X):\n",
    "        ridge.fit(X[train], y[train])\n",
    "        ypred = ridge.predict(X[test])\n",
    "        temp.append(mean_squared_error(y[test],ypred))\n",
    "    temp=np.array(temp)\n",
    "    MSE.append(temp.mean())\n",
    "    std_error.append(temp.std())\n",
    "MSE=np.array(MSE)\n",
    "std_error=np.array(std_error)\n",
    "\n",
    "#best C probably around 1 \n",
    "X_train, X_test, y_train, y_test = (train_test_split(X, y))\n",
    "ridge= Ridge(alpha=1/(2*1))\n",
    "ridge.fit(X_train, y_train)\n",
    "ypred=ridge.predict(X)\n",
    "\n",
    "import calendar\n",
    "X_labels=[];X_ticks=[]\n",
    "for i in range(1,np.size(X1, 0),12):\n",
    "    temp=('%s'%X1[i]+' %s'%calendar.month_abbr[X2[i]])\n",
    "    X_ticks.append(i)\n",
    "    X_labels.append(str(temp))\n",
    "X_labels=np.array(X_labels);X_ticks=np.array(X_ticks)\n",
    "print(X_labels[1])\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1, 1, 1)\n",
    "plt.errorbar(C_range, MSE, yerr=std_error, linewidth=3)\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Mean square error')\n",
    "plt.show()\n",
    "\n",
    "fig=plt.figure(figsize=(15, 8))\n",
    "fig.add_subplot(1, 1, 1)\n",
    "plt.plot(X[:,3], ypred[:,4], label='preds')\n",
    "plt.plot(X[:,3], y[:,4], linestyle='dashed',label='actual values')\n",
    "#plt.xticks(range(24025, 24268, 12),X_labels[60:None], rotation=20)\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 680.2007771264011, tolerance: 0.7590609884318766\n",
      "  positive)\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2206.4450299303935, tolerance: 1.4452349203084833\n",
      "  positive)\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1668.5553775201113, tolerance: 1.141928849614396\n",
      "  positive)\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 693.1091473204825, tolerance: 0.8313389460154242\n",
      "  positive)\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 809.1351670638754, tolerance: 0.7250407776349614\n",
      "  positive)\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1190583.731524426, tolerance: 319.44861671079695\n",
      "  positive)\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2074.259057595846, tolerance: 1.268325005462725\n",
      "  positive)\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1280.9007214190856, tolerance: 0.4093594254498715\n",
      "  positive)\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25536.308760067244, tolerance: 8.99876503856041\n",
      "  positive)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "append() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-908e03cc68a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mlasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0myp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mte\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mte\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: append() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "#Lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "C = [1, 2, 10, 25, 2]\n",
    "m =[]\n",
    "s = []\n",
    "for c in C:\n",
    "    lasso = Lasso(alpha=1/c)\n",
    "    k = KFold(n_splits=5)\n",
    "    t = []\n",
    "    for tr, te in kf.split(X):\n",
    "        lasso.fit(X[tr], y[tr])   \n",
    "        yp = lasso.predict(X[te])\n",
    "        t.append(mean_squared_error(y[te], yp))\n",
    "    t = np.array(t)\n",
    "    m.append(t.mean())\n",
    "    s.append(t.std())\n",
    "    print(lasso.score(X[te], y[te]))\n",
    "plt.errorbar(C, m, yerr=s, linewidth=3)\n",
    "plt.xlabel('C values')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()\n",
    "#plt.plot(X[te][:,3], yp[:,1], label='preds')\n",
    "#plt.plot(X[te][:,3], y[te][:,1], label='actual values')\n",
    "plt.legend()\n",
    "\n",
    "#Lasso Cross-Validated\n",
    "k = KFold(n_splits=5)\n",
    "for tr, te in kf.split(X):\n",
    "        lasso.fit(X[tr], y[tr])   \n",
    "        yp = lasso.predict(X[te])\n",
    "plt.plot(X[te][:,3], yp[:,1], label='preds')\n",
    "plt.plot(X[te][:,3], y[te][:,1], label='actual values')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1980*12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
